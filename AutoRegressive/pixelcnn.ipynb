{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* PixelCNN 은 PixelRNN 논문에서 처음 소개됨. 즉 따로 PixelCNN 논문이 있는것은 아님.  \n",
    "* 해당 논문의 이름처럼 그 논문에서 최고 성능은 digonal BiLSTM PixelRNN 이었으나, PixelCNN 의 낮은 computational cost 때문에, 즉 가성비 때문에 그 이후로 PixelCNN 을 발전시킨 conditional PixelCNN, PixelCNN++ 등이 제안됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### References\n",
    "\n",
    "* https://tensorflow.blog/2016/11/29/pixelcnn-1601-06759-summary/\n",
    "    * https://github.com/rickiepark/pixel-rnn-tensorflow/blob/pixel-cnn/pixel-cnn.py\n",
    "* https://github.com/carpedm20/pixel-rnn-tensorflow\n",
    "\n",
    "개선참조 (위 참조를 통해 구현 후 아래 참조를 통해 개선함)\n",
    "\n",
    "* https://github.com/igul222/pixel_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mask_conv(inputs, filters, mask_type, kernel_size=[3,3], strides=1, name='mask-conv', activ_fn=None):\n",
    "    with tf.variable_scope(name):\n",
    "        kernel_h, kernel_w = kernel_size\n",
    "        assert kernel_h % 2 == 1 and kernel_w % 2 == 1, \"kernel height and width should be odd number\"\n",
    "        center_h = kernel_h // 2\n",
    "        center_w = kernel_w // 2\n",
    "        \n",
    "        # tf.nn.conv2d 에서 사용하는 kernel 의 shape 이 아래처럼 생김.\n",
    "        # (kernel_height, kernel_width, input_channel_size, output_channel_size)\n",
    "        # NHWC 로 가정하여 input_channel_size 를 아래처럼 구함.\n",
    "        entire_kernel_shape = (kernel_h, kernel_w, inputs.shape[-1], filters)\n",
    "        mask = np.ones(entire_kernel_shape, dtype=np.float32)\n",
    "        mask[center_h, center_w+1:, :, :] = 0\n",
    "        mask[center_h+1:, :, :, :] = 0\n",
    "        # Q. A 일때가 이렇게 되는건가?\n",
    "        # A. 맞음. 왜냐면 어차피 이건 이전 레이어에서 가져오는 거기 때문에...\n",
    "        if mask_type == 'A':\n",
    "            mask[center_h, center_w, :, :] = 0\n",
    "        \n",
    "        weight = tf.get_variable(\"weight\", entire_kernel_shape, tf.float32,\n",
    "                                 tf.contrib.layers.variance_scaling_initializer())\n",
    "        weight *= tf.constant(mask, dtype=tf.float32)\n",
    "        \n",
    "        bias = tf.get_variable(\"bias\", [filters], tf.float32, tf.zeros_initializer())\n",
    "        with tf.variable_scope('conv'):\n",
    "            outputs = tf.nn.conv2d(inputs, weight, strides=[1, strides, strides, 1], padding='SAME')\n",
    "            # bias 는 커널(필터) 당 하나씩 있음!\n",
    "#             print outputs.shape # (?, 28, 28, 64)\n",
    "#             print bias.shap # (64,)\n",
    "            outputs = tf.nn.bias_add(outputs, bias)\n",
    "        \n",
    "        if activ_fn:\n",
    "            outputs = activ_fn(outputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "이건 이해가 안 됨.\n",
    "continuous distribution => discrete distribution 으로 바꾸는 작업인데...\n",
    "이걸 왜 이렇게 랜덤하게 바꾸지?\n",
    "\n",
    "그냥 해석해보면,\n",
    "uniform distribution 을 쓰니까, 결국 자기 픽셀값에 따라 0/1 이 확률적으로 정해지게 됨.\n",
    "즉, 0.7 인 값은 0.7 의 확률로 1이 됨. 0.3의 확률로 0이 되고.\n",
    "\n",
    "그런갑지... 논문을 더 자세히 봐야겠다.\n",
    "\"\"\"\n",
    "def binarize(images):\n",
    "    return (np.random.uniform(size=images.shape) < images).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model spec\n",
    "\n",
    "* phase 1\n",
    "    * 7x7 conv mask A\n",
    "* phase 2\n",
    "    * 3x3 conv mask B \\* 15 layers\n",
    "    * residual connection\n",
    "* phase 3\n",
    "    * 1x1 conv mask B \\* 2 layers\n",
    "* readout (phase 4)\n",
    "    * dim matching (1x1 conv, without mask) - 단, 1x1 conv 에서는 mask B 가 no mask conv 와 동일해서 그냥 그걸 씀\n",
    "    * softmax (256-color) or sigmoid (mnist)\n",
    "    \n",
    "no pooling layers (no downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_filters = 64\n",
    "n_filters_out = 64\n",
    "n_conv_layers = 7\n",
    "n_out_layers = 2\n",
    "\n",
    "train_steps = mnist.train.num_examples // batch_size\n",
    "test_steps = mnist.test.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build_net\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "x_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "# phase 1\n",
    "net = mask_conv(x_img, n_filters, mask_type='A', kernel_size=[7,7], name='p1-convA')\n",
    "\n",
    "# phase 2\n",
    "for i in range(n_conv_layers):\n",
    "    net = mask_conv(net, n_filters, mask_type='B', kernel_size=[3,3], name='p2-convB{}'.format(i), activ_fn=tf.nn.relu)\n",
    "\n",
    "# phase 3\n",
    "for i in range(n_out_layers):\n",
    "    net = mask_conv(net, n_filters_out, mask_type='B', kernel_size=[1,1], name='p3-1x1convB{}'.format(i), activ_fn=tf.nn.relu)\n",
    "\n",
    "# phase 4\n",
    "# grad clipping 을 해줘야되나? 원소스에는 있음. 논문에는 별 얘기 없는거같은뎅\n",
    "logits = mask_conv(net, 1, mask_type='B', kernel_size=[1,1], name='logits')\n",
    "y_pred = tf.nn.sigmoid(logits)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=x_img))\n",
    "# train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\"\"\"graident clipping\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "new_grads_and_vars = [(tf.clip_by_value(gv[0], -1, 1), gv[1]) for gv in grads_and_vars]\n",
    "optim = optimizer.apply_gradients(new_grads_and_vars)\n",
    "\"\"\"\n",
    "optim = tf.train.AdamOptimizer()\n",
    "grads_and_vars = optim.compute_gradients(loss)\n",
    "new_grads_and_vars = [(tf.clip_by_value(gv[0], -1, 1), gv[1]) for gv in grads_and_vars]\n",
    "train_op = optim.apply_gradients(new_grads_and_vars)\n",
    "\n",
    "summary_op = tf.summary.merge([\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "#     plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/300] train_loss: 0.1572 / test_loss: 0.1204\n",
      "[2/300] train_loss: 0.1199 / test_loss: 0.1185\n",
      "[3/300] train_loss: 0.1183 / test_loss: 0.1168\n",
      "[4/300] train_loss: 0.1175 / test_loss: 0.1163\n",
      "[5/300] train_loss: 0.1168 / test_loss: 0.1156\n",
      "[6/300] train_loss: 0.1163 / test_loss: 0.1153\n",
      "[7/300] train_loss: 0.1160 / test_loss: 0.1147\n",
      "[8/300] train_loss: 0.1156 / test_loss: 0.1145\n",
      "[9/300] train_loss: 0.1154 / test_loss: 0.1152\n",
      "[10/300] train_loss: 0.1151 / test_loss: 0.1144\n",
      "[11/300] train_loss: 0.1149 / test_loss: 0.1142\n",
      "[117/300] train_loss: 0.1111 / test_loss: 0.1106\n",
      "[118/300] train_loss: 0.1111 / test_loss: 0.1108\n",
      "[190/300] train_loss: 0.1109 / test_loss: 0.1106\n",
      "[191/300] train_loss: 0.1108 / test_loss: 0.1105\n",
      "[192/300] train_loss: 0.1108 / test_loss: 0.1105\n",
      "[193/300] train_loss: 0.1109 / test_loss: 0.1107\n",
      "[194/300] train_loss: 0.1108 / test_loss: 0.1105\n",
      "[195/300] train_loss: 0.1108 / test_loss: 0.1105\n",
      "[196/300] train_loss: 0.1108 / test_loss: 0.1104\n",
      "[197/300] train_loss: 0.1108 / test_loss: 0.1107\n",
      "[198/300] train_loss: 0.1109 / test_loss: 0.1102\n",
      "[199/300] train_loss: 0.1108 / test_loss: 0.1105\n",
      "[200/300] train_loss: 0.1109 / test_loss: 0.1105\n",
      "[201/300] train_loss: 0.1107 / test_loss: 0.1105\n",
      "[202/300] train_loss: 0.1109 / test_loss: 0.1103\n",
      "[203/300] train_loss: 0.1108 / test_loss: 0.1109\n",
      "[204/300] train_loss: 0.1107 / test_loss: 0.1105\n",
      "[205/300] train_loss: 0.1109 / test_loss: 0.1102\n",
      "[206/300] train_loss: 0.1107 / test_loss: 0.1105\n",
      "[207/300] train_loss: 0.1108 / test_loss: 0.1103\n",
      "[208/300] train_loss: 0.1108 / test_loss: 0.1104\n",
      "[209/300] train_loss: 0.1108 / test_loss: 0.1106\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "epoch_n = 300\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# writer\n",
    "train_writer = tf.summary.FileWriter('summary/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('summary/test')\n",
    "\n",
    "for epoch in range(epoch_n):\n",
    "    # train\n",
    "    train_loss = 0.\n",
    "    test_loss = 0.\n",
    "    for i in range(train_steps):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        images = binarize(batch[0])\n",
    "        _, cur_loss, cur_summary = sess.run([train_op, loss, summary_op], {X: images})\n",
    "        train_loss += cur_loss\n",
    "        train_writer.add_summary(cur_summary, epoch)\n",
    "\n",
    "    # test\n",
    "    for i in range(test_steps):\n",
    "        batch = mnist.test.next_batch(batch_size)\n",
    "        images = binarize(batch[0])\n",
    "        cur_loss, cur_summary = sess.run([loss, summary_op], {X: images})\n",
    "        test_writer.add_summary(cur_summary, epoch)\n",
    "        test_loss += cur_loss\n",
    "\n",
    "    train_loss /= train_steps\n",
    "    test_loss /= test_steps\n",
    "    print \"[{}/{}] train_loss: {:.4f} / test_loss: {:.4f}\".format(epoch+1, epoch_n, train_loss, test_loss)\n",
    "\n",
    "    # generate samples\n",
    "    if epoch == 0 or (epoch+1)%10 == 0:\n",
    "        samples = np.zeros((16, 784), dtype='float32')\n",
    "        gen_image = np.zeros((16, 784), dtype='float32')\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                for k in range(1):\n",
    "                    # 이렇게 하는건 좀 비효율적인게 아닌가 시픈댕\n",
    "                    # 한픽셀을 제너레이트 하기 위해서 전체 이미지를 다 제너레이트함...\n",
    "                    # 근데 뭐 이걸 개선하려면 골때릴듯...\n",
    "                    pos = i*28 + j\n",
    "                    cur_gen_image = sess.run(y_pred, {X: samples})\n",
    "                    next_samples = binarize(cur_gen_image) # random noise 역할을 하겠네\n",
    "                    samples[:, pos] = next_samples[:, i, j, k]\n",
    "                    gen_image[:, pos] = cur_gen_image[:, i, j, k]\n",
    "\n",
    "        fig = plot(samples) # binarized\n",
    "#         plot(gen_image) # generated images without binarized\n",
    "#         plot(cur_gen_image.reshape(16, 784)) # last one-shot generated images\n",
    "        plt.savefig('out/{:0>4d}.png'.format(epoch), bbox_inches='tight')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 - tf 1.1",
   "language": "python",
   "name": "python2-tf1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
