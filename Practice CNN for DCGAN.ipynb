{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with BN in TensorFlow\n",
    "\n",
    "* DCGAN 의 CNN 모델을 만들어서 MNIST classification 을 수행해보자. \n",
    "* TF 에서 BN 을 적용하는 걸 연습하는 용도. \n",
    "* MNIST 로 정확도를 테스트하기 어렵다면 다른 데이터셋도 구해서 적용해보자.\n",
    "\n",
    "Discriminator of DCGAN:\n",
    "\n",
    "![Discriminator of DCGAN](http://bamos.github.io/data/2016-08-09/discrim-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_init(shape):\n",
    "    return tf.truncated_normal(shape, stddev=0.1)\n",
    "\n",
    "def bias_init(shape):\n",
    "    return tf.constant(0.1, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 참조한 image completion 코드에서는 다른 식으로 구현하는데, 그게 더 빠른가?\n",
    "# 특이하게 구현함. https://github.com/bamos/dcgan-completion.tensorflow/blob/master/ops.py\n",
    "def lrelu(x, leak=0.2):\n",
    "    return tf.maximum(x, x*leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 일단 MNIST datset 은 28x28x1 이므로, \n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# reshape for CNN\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "# first conv layer: \n",
    "W1 = tf.Variable(weight_init([5, 5, 1, 64]))\n",
    "b1 = tf.Variable(bias_init([64]))\n",
    "\n",
    "a1 = tf.nn.conv2d(X_img, W1, strides=[1, 2, 2, 1], padding='SAME') + b1\n",
    "h1 = lrelu(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Maximum:0' shape=(?, 14, 14, 64) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W2 = tf.Variable(weight_init([5, 5, 64, 128]))\n",
    "b2 = tf.Variable(bias_init([128]))\n",
    "\n",
    "a2 = tf.nn.conv2d(h1, W2, strides=[1, 2, 2, 1], padding='SAME') + b2\n",
    "h2 = lrelu(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Maximum_1:0' shape=(?, 7, 7, 128) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W3 = tf.Variable(weight_init([5, 5, 128, 256]))\n",
    "b3 = tf.Variable(bias_init([256]))\n",
    "\n",
    "a3 = tf.nn.conv2d(h2, W3, strides=[1, 2, 2, 1], padding='SAME') + b3\n",
    "h3 = lrelu(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Maximum_3:0' shape=(?, 4, 4, 256) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FC layer. 원래 더 해야 하지만 이건 MNIST 니까 여기까지만 하자.\n",
    "# 원래는 sigmoid 로 0/1 만 판별하는데, MNIST 는 10개니까 softmax 로 해야함\n",
    "\n",
    "W4 = tf.Variable(weight_init([4096, 10]))\n",
    "b4 = tf.Variable(bias_init([10]))\n",
    "h3_flat = tf.reshape(h3, [-1, 4096])\n",
    "\n",
    "# last layer activation = logit\n",
    "logits = tf.matmul(h3_flat, W4) + b4\n",
    "y_prob = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "solver = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = tf.argmax(logits, axis=1)\n",
    "correction = tf.equal(pred, tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1] train: 0.21900 / test: 0.37174 | [acc] train: 0.8900 / test: 0.8946\n",
      "[  2] train: 0.03331 / test: 0.31657 | [acc] train: 0.9100 / test: 0.9061\n",
      "[  3] train: 0.02625 / test: 0.22063 | [acc] train: 0.9200 / test: 0.9349\n",
      "[  4] train: 0.02256 / test: 0.18872 | [acc] train: 0.9300 / test: 0.9415\n",
      "[  5] train: 0.01758 / test: 0.16194 | [acc] train: 0.9200 / test: 0.9521\n",
      "[  6] train: 0.01824 / test: 0.14636 | [acc] train: 0.9500 / test: 0.9557\n",
      "[  7] train: 0.01499 / test: 0.14213 | [acc] train: 0.9500 / test: 0.9554\n",
      "[  8] train: 0.01541 / test: 0.10929 | [acc] train: 0.9800 / test: 0.9651\n",
      "[  9] train: 0.01411 / test: 0.12993 | [acc] train: 0.9700 / test: 0.9584\n",
      "[ 10] train: 0.01096 / test: 0.08974 | [acc] train: 0.9900 / test: 0.9733\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_batch = mnist.train.num_examples / batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_sum = 0\n",
    "    for i in range(total_batch / 10):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        loss_cur, _ = sess.run([loss, solver], feed_dict={X: batch[0], Y: batch[1]})\n",
    "        loss_sum += np.average(loss_cur)\n",
    "    \n",
    "#     train_loss = np.average(loss_cur)\n",
    "    train_loss = loss_sum / total_batch\n",
    "    test_batch = mnist.test.next_batch(10000)\n",
    "    test_loss = np.average(sess.run(loss, feed_dict={X: test_batch[0], Y: test_batch[1]}))\n",
    "    \n",
    "    train_acc = sess.run(accuracy, {X:batch[0], Y:batch[1]})\n",
    "    test_acc = sess.run(accuracy, {X:test_batch[0], Y:test_batch[1]})\n",
    "    print(\"[{:3}] train: {:.5f} / test: {:.5f} | [acc] train: {:.4f} / test: {:.4f}\"\n",
    "          .format(epoch+1, train_loss, test_loss, train_acc, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
