{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBGAN\n",
    "\n",
    "Zhao, Junbo, Michael Mathieu, and Yann LeCun. \"Energy-based generative adversarial network.\" arXiv preprint arXiv:1609.03126 (2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy-model\n",
    "\n",
    "* data manifold 에 가까운 지역에는 낮은 에너지를 할당하고, 다른 지역에는 높은 에너지를 할당\n",
    "* 다른 모델이 (like MLE) data manifold 를 찾는데 집중할 뿐 다른 지역에는 신경쓰지 않는것과 대조됨\n",
    "* [다만, 이 모델이 특별히 다른 모델보다 energy-based 냐 라는 비판](http://www.inference.vc/are-energy-based-gans-actually-energy-based/)도 있음 - by Ferenc\n",
    "\n",
    "$$\\begin{align}\n",
    "L_D(x,z)&=D(x)+[m-D(G(z))]^+ \\\\\n",
    "L_G(z)&=D(G(z))\n",
    "\\end{align}$$\n",
    "\n",
    "where $[\\cdot]^+ = max(0,\\cdot)$ - hinge loss (margin loss).\n",
    "\n",
    "* hinge loss 를 사용함으로써 D 는 '적당히' 만 fake sample 들에게 높은 에너지를 할당\n",
    "* G 는 그런거 없고 최대한 높은 에너지를 할당하도록 학습\n",
    "* 무조건 hinge loss 를 쓸 필요는 없고 다양한 로스가 사용가능하다고는 되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use auto-encoders as discriminator\n",
    "\n",
    "$$D(x)=\\Vert Dec(Enc(x))-x \\Vert$$\n",
    "\n",
    "![ebgan-ae](ebgan-ae.png)\n",
    "    \n",
    "* 기존의 classifier 보다 latent representation 을 학습하는 AE 를 사용함으로써 G 에게 보다 유의미한 teaching 이 가능해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repelling regularizer\n",
    "\n",
    "$$\n",
    "f_{PT}(S)={1 \\over N(N-1)} \\sum_i \\sum_{j\\neq i} \\left( \\frac{S^T_i S_j}{\\Vert S_i\\Vert \\Vert S_j\\Vert} \\right)^2\n",
    "$$\n",
    "\n",
    "S is (encoded) latent representation. i, j indicates index of data point\n",
    "\n",
    "* Pulling-away term (PT)\n",
    "* same as 'minibatch discrimination' of ImprovedGAN\n",
    "* encoded representation 들 간의 cos-sim (코사인 유사도) 를 최소화한다 => 데이터 포인트 간의 representation variance 를 높게 유지한다\n",
    "* 즉, G 가 생성하는 데이터들간의 variance 를 유지함으로써 mode collapse 를 방지함\n",
    "* 이 regularizer는 G 에만 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation - simplified\n",
    "\n",
    "* MNIST\n",
    "* use fc layers\n",
    "* but implement core things - AE and PT regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "z_dim = 64\n",
    "m = 5.\n",
    "pt_weight = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        net = slim.fully_connected(z, 128)\n",
    "        logits = slim.fully_connected(net, 784, activation_fn=None)\n",
    "        prob = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lf: latent features\n",
    "def pt_regularizer(lf):\n",
    "    eps = 1e-8 # epsilon for numerical stability\n",
    "    l2_norm = tf.sqrt(tf.reduce_sum(tf.square(lf), axis=1, keep_dims=True))\n",
    "    expected_shape(l2_norm, [None, 1])\n",
    "    unit_lf = lf / (l2_norm + eps) # this is unit vector?\n",
    "    cos_sim = tf.square(tf.matmul(unit_lf, unit_lf, transpose_b=True)) # [N, h_dim] x [h_dim, N] = [N, N]\n",
    "    N = tf.cast(tf.shape(lf)[0], tf.float32) # batch_size\n",
    "    pt_loss = (tf.reduce_sum(cos_sim)-N) / (N*(N-1))\n",
    "    return pt_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse): # auto-encoder\n",
    "        # latent features lf\n",
    "        lf = slim.fully_connected(x, 128) # encoder\n",
    "        x_recon = slim.fully_connected(lf, 784, activation_fn=None) # decoder\n",
    "        mse = tf.losses.mean_squared_error(x, x_recon) # 데이터포인트마다 하는줄 알았는데 그냥 다합해서 하는건가봄\n",
    "    \n",
    "        return lf, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EBGAN():\n",
    "    def __init__(self, name, use_pt_regularizer=False):\n",
    "        with tf.variable_scope(name):\n",
    "            X = tf.placeholder(tf.float32, [None, 784])\n",
    "            z = tf.placeholder(tf.float32, [None, z_dim])\n",
    "\n",
    "            fake_logits, fake = generator(z)\n",
    "            D_real_lf, D_real_mse = discriminator(X)\n",
    "            D_fake_lf, D_fake_mse = discriminator(fake, reuse=True)\n",
    "            expected_shape(D_real_mse, []) # scalar\n",
    "            expected_shape(D_fake_mse, []) # scalar\n",
    "\n",
    "            D_fake_hinge = tf.reduce_mean(tf.maximum(0., m - D_fake_mse)) # hinge_loss\n",
    "            D_loss = D_real_mse + D_fake_hinge\n",
    "            G_loss = D_fake_mse\n",
    "            if use_pt_regularizer:\n",
    "                self.pt_loss = pt_weight * pt_regularizer(D_fake_lf) # pt_loss\n",
    "                G_loss += self.pt_loss\n",
    "\n",
    "            D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name+\"/discriminator\")\n",
    "            G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name+\"/generator\")\n",
    "\n",
    "            D_train_op = tf.train.AdamOptimizer().minimize(D_loss, var_list=D_vars)\n",
    "            G_train_op = tf.train.AdamOptimizer().minimize(G_loss, var_list=G_vars)\n",
    "\n",
    "            self.X = X\n",
    "            self.z = z\n",
    "            self.D_loss = D_loss\n",
    "            self.G_loss = G_loss\n",
    "            self.D_train_op = D_train_op\n",
    "            self.G_train_op = G_train_op\n",
    "            self.fake = fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build nets\n",
    "tf.reset_default_graph()\n",
    "\n",
    "ebgan = EBGAN('ebgan')\n",
    "reg_ebgan = EBGAN('ebgan-pt', use_pt_regularizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000000] (non-reg) D_loss: 4.8241, G_loss: 0.3175 | (reg) D_loss: 4.8458, G_loss: 1.2874, pt_loss: 0.9901\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'out/ebgan_0000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-087e6af4487c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfig2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mprint_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfig1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out/ebgan_{:0>4d}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mfig2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out/ebgan-pt_{:0>4d}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2253\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'out/ebgan_0000.png'"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "n_iter = 1000000\n",
    "print_step = 10000\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(n_iter):\n",
    "    X_batch, _ = mnist.train.next_batch(batch_size)\n",
    "    z_batch = sample_z(batch_size, z_dim)\n",
    "    _, _, D_loss_cur1, G_loss_cur1 = sess.run([ebgan.D_train_op, ebgan.G_train_op, ebgan.D_loss, ebgan.G_loss],\n",
    "                                              {ebgan.X: X_batch, ebgan.z: z_batch})\n",
    "    _, _, D_loss_cur2, G_loss_cur2, pt_loss_cur = \\\n",
    "        sess.run([reg_ebgan.D_train_op, reg_ebgan.G_train_op, reg_ebgan.D_loss, reg_ebgan.G_loss, reg_ebgan.pt_loss],\n",
    "                 {reg_ebgan.X: X_batch, reg_ebgan.z: z_batch})\n",
    "    \n",
    "    if i % print_step == 0 or i == n_iter-1:\n",
    "        print('[{}/{}] (non-reg) D_loss: {:.4f}, G_loss: {:.4f} | (reg) D_loss: {:.4f}, G_loss: {:.4f}, pt_loss: {:.4f}'.\n",
    "              format(i, n_iter, D_loss_cur1, G_loss_cur1, D_loss_cur2, G_loss_cur2, pt_loss_cur))\n",
    "        z_ = sample_z(16, z_dim)\n",
    "        samples1 = sess.run(ebgan.fake, {ebgan.z: z_})\n",
    "        samples2 = sess.run(reg_ebgan.fake, {reg_ebgan.z: z_})\n",
    "        fig1 = plot(samples1)\n",
    "        fig2 = plot(samples2)\n",
    "        c = int((i+1) / print_step)\n",
    "        fig1.savefig('out/ebgan_{:0>4d}.png'.format(c), bbox_inches='tight')\n",
    "        fig2.savefig('out/ebgan-pt_{:0>4d}.png'.format(c), bbox_inches='tight')\n",
    "        plt.close(fig1)\n",
    "        plt.close(fig2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 - tf.latest",
   "language": "python",
   "name": "python2-tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
